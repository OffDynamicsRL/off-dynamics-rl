# Welcome to ODRL

Welcome to ODRL, a benchmark for Off-Dynamics Reinforcement Learning. This tutorial will guide you through the basics of the ODRL benchmark, help you understand the core concepts and designs, and [get you started](./1_get_started.md) with your research in the context of off-dynamics RL.

## What is ODRL?

ODRL is the first benchmark for off-dynamics RL problems, in which there is a limited budget of target domain data while comparatively sufficient source domain data can be accessed. However, there exist dynamic discrepancies between the source domain and the target domain. The goal is to acquire better performance in the target domain by leveraging data from both domains.

## Audience

ODRL is based on Python, so it is suitable for Python developers (and newcomers in RL!!). Please get yourself familiar with Python before diving into APPL. If you are new to Python, you can start with the [official Python tutorial](https://docs.python.org/3/tutorial/index.html).